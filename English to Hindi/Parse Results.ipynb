{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name = \"D:/NLP Project/Hindi English/test_results1.txt\"\n",
    "file_content = {}\n",
    "i = 0\n",
    "\n",
    "for j in range(1, 11):\n",
    "    file_name = \"D:/NLP Project/Hindi English/test_results\"+str(j)+\".txt\"\n",
    "    with codecs.open(file_name, encoding=\"utf-8\", mode=\"r\") as fp:\n",
    "        line = fp.readline()\n",
    "        while len(line) > 0:\n",
    "            if line.startswith('Input'):\n",
    "                i += 1\n",
    "                start = line.index('-')\n",
    "                content = line[start+1:]\n",
    "                file_content[i] = {}\n",
    "                file_content[i]['I'] = content.strip()\n",
    "            if line.startswith('Actual'):\n",
    "                start = line.index('-')\n",
    "                content = line[start+1:]\n",
    "                file_content[i]['X'] = content.strip()\n",
    "            if line.startswith('Predicted'):\n",
    "                start = line.index('-')\n",
    "                content = line[start+1:]\n",
    "                file_content[i]['Y'] = content.strip()\n",
    "            line = fp.readline()\n",
    "\n",
    "pickle.dump(file_content, open(\"D:/NLP Project/Hindi English/test_data.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39382751594505677\n"
     ]
    }
   ],
   "source": [
    "bleu_scores = []\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "cc = SmoothingFunction()\n",
    "for i in range(1, 10001):\n",
    "    actual_output = file_content[i]['X']\n",
    "    predicted_output = file_content[i]['Y']\n",
    "    references = actual_output.split(' ')\n",
    "    hypothesis = predicted_output.split(' ')\n",
    "    if len(references) >= 4 and len(hypothesis) >= 4:\n",
    "        BLEUscore = nltk.translate.bleu_score.sentence_bleu([references], hypothesis, smoothing_function=cc.method2)\n",
    "    elif len(references) >= 3 and len(hypothesis) >= 3:\n",
    "        BLEUscore = nltk.translate.bleu_score.sentence_bleu([references], hypothesis, weights = (1.0/3, 1.0/3, 1.0/3), smoothing_function=cc.method2)\n",
    "    elif len(references) >= 2 and len(hypothesis) >= 2:\n",
    "        BLEUscore = nltk.translate.bleu_score.sentence_bleu([references], hypothesis, weights = (0.5, 0.5), smoothing_function=cc.method2)\n",
    "    else:\n",
    "        BLEUscore = nltk.translate.bleu_score.sentence_bleu([references], hypothesis, weights = [1], smoothing_function=cc.method2)\n",
    "    bleu_scores.append(BLEUscore)\n",
    "\n",
    "print(sum(bleu_scores)/float(len(bleu_scores)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
